version: '3.8'

services:
  # 后端 (合并了 API 和 Worker, 使用 BackgroundTasks 模式)
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    container_name: markpdfdown-backend
    restart: always
    environment:
      # LLM 提供商配置
      - LLM_PROVIDER=${LLM_PROVIDER:-gemini}
      - LLM_MODEL=${LLM_MODEL:-gemini-3.0-flash-exp}
      - LLM_CONCURRENCY=${LLM_CONCURRENCY:-2}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.3}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS:-8192}
      - LLM_MAX_TASKS=${LLM_MAX_TASKS:-20}
      # API 密钥（从 .env 文件读取）
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      # API 基础 URL
      - LLM_BASE_URL=${LLM_BASE_URL:-}
      - OPENAI_API_BASE=${OPENAI_API_BASE:-}
      # Docker 配置
      - USE_CELERY=${USE_CELERY:-false}
      - PYTHONPATH=/app/backend:/app/markpdfdown_core/src
    volumes:
      - ./backend/files:/app/backend/files      # 转换产物
      - ./backend/tasks.db:/app/backend/tasks.db # 任务记录
      - ./backend/.env:/app/backend/.env        # 环境配置
    ports:
      - "127.0.0.1:18000:8000"

  # 前端 (提供网页界面)
  frontend:
    build:
      context: ./frontend
    container_name: markpdfdown-frontend
    restart: always
    ports:
      - "127.0.0.1:18080:80"
    depends_on:
      - backend