import asyncio
import logging
import os
import sys
from concurrent.futures import ThreadPoolExecutor
from typing import List
from pathlib import Path

# æ·»åŠ markpdfdown_coreåˆ°Pythonè·¯å¾„
backend_dir = Path(__file__).parent.parent.parent
core_src_dir = backend_dir.parent / "markpdfdown_core" / "src"
if str(core_src_dir) not in sys.path:
    sys.path.insert(0, str(core_src_dir))

# Import from core using expected path (assuming PYTHONPATH is set)
from markpdfdown.core.file_worker import create_worker
from markpdfdown.core.llm_client import LLMClient
from markpdfdown.config import config

logger = logging.getLogger(__name__)

# ...

class SmartWorker:
    def __init__(self, model_name: str, concurrency: int = 2, api_key: str = None, base_url: str = None, progress_callback=None):
        self.concurrency = concurrency
        self.progress_callback = progress_callback  # è¿›åº¦å›è°ƒå‡½æ•°

        # å¤„ç†æ¨¡å‹åç§°æ ¼å¼ï¼Œç¡®ä¿ç¬¦åˆ litellm è§„èŒƒ
        # litellm éœ€è¦ provider/model æ ¼å¼ï¼Œå¦‚ gemini/gemini-2.0-flash
        if model_name.startswith("gemini") and not model_name.startswith("gemini/"):
            # ä¸º Gemini æ¨¡å‹æ·»åŠ  gemini/ å‰ç¼€
            self.model_name = f"gemini/{model_name}"
        elif model_name.startswith("claude") and not model_name.startswith("anthropic/"):
            # Claude æ¨¡å‹å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼Œlitellm ä¼šè‡ªåŠ¨å¤„ç†
            self.model_name = model_name
        else:
            self.model_name = model_name

        # Determine provider to set correct env var
        # Basic mapping for common providers
        if api_key:
            if model_name.startswith("gpt"):
                os.environ["OPENAI_API_KEY"] = api_key
            elif model_name.startswith("claude"):
                os.environ["ANTHROPIC_API_KEY"] = api_key
            elif model_name.startswith("gemini"):
                os.environ["GEMINI_API_KEY"] = api_key
            elif "ollama" in model_name:
                pass # Ollama usually doesn't need key, or used in base_url
            else:
                # Default fallback or custom provider
                os.environ["OPENAI_API_KEY"] = api_key

        if base_url:
            os.environ["OPENAI_API_BASE"] = base_url

        self.llm_client = LLMClient(self.model_name)

    async def process_file(self, input_path: str, task_id: str = None) -> tuple[str, int]:
        """
        Process a file using a streaming pipeline with per-page markdown saving.

        æ¶æ„æ”¹è¿›:
        1. æ¯è½¬æ¢å®Œä¸€é¡µï¼Œç«‹å³ä¿å­˜è¯¥é¡µé¢çš„ markdown æ–‡ä»¶ (page_0001.md)
        2. å®ç°å®æ—¶é¢„è§ˆ - æ¯é¡µå®Œæˆåå³å¯æŸ¥çœ‹
        3. æœ€ååˆå¹¶æ‰€æœ‰é¡µé¢ä¸ºå®Œæ•´çš„ markdown æ–‡ä»¶

        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            task_id: ä»»åŠ¡ID (ç”¨äºè¿›åº¦å›è°ƒ)

        Returns:
            (markdown_content, total_pages): Markdown å†…å®¹å’Œæ€»é¡µæ•°
        """
        logger.info(f"Processing file (Streaming Mode with Per-Page Saving): {input_path}")

        # è·å–è¾“å‡ºç›®å½•
        output_dir = os.path.dirname(input_path)

        try:
             worker = create_worker(input_path)
             # image_gen is a generator (one page at a time)
             image_gen = worker.convert_to_images()
        except Exception as e:
            logger.error(f"Failed to initialize worker: {e}")
            raise

        # Parallel conversion with Semaphore to control concurrency
        tasks = []
        semaphore = asyncio.Semaphore(self.concurrency)
        completed_count = 0
        total_pages = 0
        total_input_tokens = 0
        total_output_tokens = 0

        async def _wrapped_convert(index: int, img_path: str):
            nonlocal completed_count, total_input_tokens, total_output_tokens
            async with semaphore:
                try:
                    # Wrap blocking _convert_one into thread for true async in loop
                    loop = asyncio.get_running_loop()
                    result = await loop.run_in_executor(None, self._convert_one, img_path)

                    # Extract content and tokens from result
                    if hasattr(result, 'content'):
                        content = result.content
                        total_input_tokens += result.input_tokens
                        total_output_tokens += result.output_tokens
                    else:
                        # å…¼å®¹æ—§ç‰ˆæœ¬ï¼Œå¦‚æœè¿”å›çš„æ˜¯å­—ç¬¦ä¸²
                        content = result

                    # Simple data cleaning to prevent mojibake/overflow issues
                    if not content or len(content.strip()) == 0:
                        content = ""

                    content = content.strip()

                    # âœ¨ æ¶æ„æ”¹è¿›: ç«‹å³ä¿å­˜æ¯é¡µçš„ markdown æ–‡ä»¶
                    # è¿™æ ·å‰ç«¯å¯ä»¥å®æ—¶è·å–å’Œé¢„è§ˆæ¯ä¸ªé¡µé¢çš„å†…å®¹
                    page_num = index + 1
                    page_md_path = os.path.join(output_dir, f"page_{page_num:04d}.md")

                    try:
                        # ä½¿ç”¨åŸå­æ“ä½œï¼šå…ˆå†™ä¸´æ—¶æ–‡ä»¶ï¼Œå†é‡å‘½å
                        page_md_tmp = page_md_path + ".tmp"
                        with open(page_md_tmp, "w", encoding="utf-8") as f:
                            f.write(content)
                        # åŸå­æ€§é‡å‘½åï¼ˆOS çº§åˆ«çš„åŸå­æ“ä½œï¼‰
                        os.replace(page_md_tmp, page_md_path)
                        logger.info(f"Page {page_num} markdown saved to: {page_md_path}")
                    except Exception as e:
                        logger.error(f"Failed to save page {page_num} markdown: {e}")

                    # æ›´æ–°è¿›åº¦
                    completed_count += 1
                    if self.progress_callback and task_id:
                        progress = (completed_count / total_pages * 100) if total_pages > 0 else 0
                        await self.progress_callback(
                            task_id=task_id,
                            current_page=completed_count,
                            total_pages=total_pages,
                            progress=progress,
                            status="processing"
                        )

                    return index, content
                except Exception as e:
                    logger.error(f"Task failed for page {index+1}: {e}")
                    return index, f"<!-- Error processing page {index+1} -->"

        # Read specific pages from generator (Streaming start)
        try:
            for i, img_path in enumerate(image_gen):
                total_pages = i + 1  # æ›´æ–°æ€»é¡µæ•°
                logger.info(f"Page {i+1} rendered. Dispatching recognition task...")
                task = asyncio.create_task(_wrapped_convert(i, img_path))
                tasks.append(task)

                # å‘é€åˆå§‹è¿›åº¦
                if self.progress_callback and task_id and i == 0:
                    await self.progress_callback(
                        task_id=task_id,
                        current_page=0,
                        total_pages=total_pages,
                        progress=0,
                        status="processing"
                    )
        except Exception as e:
            logger.error(f"Error during image generation: {e}")

        if not tasks:
            logger.warning("No pages were generated for processing.")
            return ""

        # Wait for all tasks to complete
        logger.info(f"All {len(tasks)} pages dispatched. Waiting for recognition results...")
        results = await asyncio.gather(*tasks)

        # Sort results by index to ensure strictly correct order
        # This prevents the "out of order" or "interleaved" data corruption
        sorted_results = sorted(results, key=lambda x: x[0])

        # âœ¨ æ”¹è¿›çš„åˆå¹¶é€»è¾‘:
        # 1. ä»ä¿å­˜çš„æ¯é¡µ markdown æ–‡ä»¶ä¸­è¯»å–å†…å®¹
        # 2. åœ¨æ¯é¡µä¹‹é—´æ·»åŠ é¡µç åˆ†éš”ç¬¦
        # 3. åˆå¹¶ä¸ºæœ€ç»ˆçš„ markdown æ–‡ä»¶
        markdown_parts = []
        for index, _ in sorted_results:
            page_num = index + 1
            page_md_path = os.path.join(output_dir, f"page_{page_num:04d}.md")

            try:
                # è¯»å–æ¯é¡µä¿å­˜çš„ markdown æ–‡ä»¶
                with open(page_md_path, "r", encoding="utf-8") as f:
                    page_content = f.read()

                # æ·»åŠ é¡µç åˆ†éš”ç¬¦
                page_marker = f"\n\n<!-- PAGE {page_num} -->\n\n"
                markdown_parts.append(page_marker + page_content)

                logger.info(f"Page {page_num} content loaded for merging")
            except Exception as e:
                logger.error(f"Failed to read page {page_num} markdown: {e}")

        # åˆå¹¶æ‰€æœ‰é¡µé¢
        final_markdown = "".join(markdown_parts)
        logger.info(f"File processing complete. Total pages merged: {len(sorted_results)}")

        # å‘é€å®Œæˆè¿›åº¦
        if self.progress_callback and task_id:
            await self.progress_callback(
                task_id=task_id,
                current_page=total_pages,
                total_pages=total_pages,
                progress=100,
                status="completed"
            )

        logger.info(f"Processing completed. Total pages: {total_pages}")
        logger.info(f"Token usage - Input: {total_input_tokens}, Output: {total_output_tokens}, Total: {total_input_tokens + total_output_tokens}")
        return final_markdown, total_pages, total_input_tokens, total_output_tokens

    def _convert_one(self, image_path: str) -> 'CompletionResult':
        """
        Single image conversion (runs in thread)

        Returns:
            CompletionResult with content and token usage
        """
        logger.info(f"ğŸ”„ Starting conversion for: {image_path}")
        logger.info(f"ğŸ“ Using model: {self.model_name}")

        system_prompt = """
You are a helpful assistant that can convert images to Markdown format. You are given an image, and you need to convert it to Markdown format. Please output the Markdown content only, without any other text.
"""
        user_prompt = """
Below is the image of one page of a document, please read the content in the image and transcribe it into plain Markdown format. Please note:
1. Identify heading levels, text styles, formulas, and the format of table rows and columns
2. Mathematical formulas should be transcribed using LaTeX syntax, ensuring consistency with the original
3. Please output the Markdown content only, without any other text.
"""
        try:
            logger.info(f"ğŸ“¤ Calling LLM API with image: {image_path}")
            result = self.llm_client.completion(
                user_message=user_prompt,
                system_prompt=system_prompt,
                image_paths=[image_path],
                temperature=config.temperature,
                max_tokens=config.max_tokens,
                retry_times=config.retry_times # Reusing config for now
            )
            logger.info(f"âœ… LLM API call successful for {image_path}, result length: {len(result.content) if result and result.content else 0}")
            logger.info(f"ğŸ“Š Tokens: Input={result.input_tokens}, Output={result.output_tokens}, Total={result.total_tokens}")
            return result
        except Exception as e:
            logger.error(f"âŒ Error converting {image_path}: {e}")
            logger.error(f"âŒ Exception type: {type(e).__name__}")
            # è¿”å›ç©ºçš„ CompletionResult è€Œä¸æ˜¯ç©ºå­—ç¬¦ä¸²
            from markpdfdown.core.llm_client import CompletionResult
            return CompletionResult(content="")
