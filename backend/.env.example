# MarkPDFdown Server LLM Configuration
# 这是配置模板，复制此文件为 .env 并填入真实值

# LLM 提供商配置
LLM_PROVIDER="gemini"
LLM_MODEL="gemini-3.0-flash-exp"
LLM_CONCURRENCY=2
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=8192
LLM_MAX_TASKS=20

# API 密钥（根据提供商选择一个填写）
# Google Gemini
GEMINI_API_KEY="your-gemini-api-key-here"

# OpenAI
OPENAI_API_KEY="your-openai-api-key-here"

# Anthropic Claude
ANTHROPIC_API_KEY="your-anthropic-api-key-here"

# Ollama (本地模型，不需要 key)
# OLLAMA_BASE_URL="http://localhost:11434"

# API 基础 URL（如果使用代理或自定义端点）
LLM_BASE_URL=""
OPENAI_API_BASE=""

# Docker 配置
USE_CELERY=false

# 注意事项：
# 1. 复制此文件为 .env: cp backend/.env.example backend/.env
# 2. 填入你的真实 API Key
# 3. 不要将 .env 提交到 Git
# 4. .env 文件已在 .gitignore 中被忽略
